# Задание на практическую работу по модулю Kafka

## Процесс выполнения
1. Создание zookeeper
```bash
bin/zookeeper-server-start.sh config/zookeeper.properties
```
2. Создание брокера
```bash
bin/kafka-server-start.sh config/server.properties
```
3. Создание топика
```bash
bin/kafka-topics.sh --create --topic transactions-topic --bootstrap-server localhost:9092 --partitions 6 --replication-factor 1
```
4. Создание производителя
```bash
bin/kafka-console-producer.sh --topic transactions-topic --bootstrap-server localhost:9092
```
5. Создание потребителя
```bash
bin/kafka-console-consumer.sh --topic transactions-topic --from-beginning --bootstrap-server localhost:9092
```

## Реализация
1. Валидатор соответствия объекта схеме
2. Сериализатор объекта
3. Распределение объектов по партициям
4. Реализация сервиса отправки
5. Вынос настроек прооизводителя в property-файлы
6. Написание тестов


### Задание #1 (Производители Kafka)
- Необходимо реализовать модуль для загрузки объектов в Kafka;
- Конфигурирование производителя должно быть вынесено в property-файл;
- В качестве данных необходимо сформировать объекты, описывающие транзакцию (тип операции/сумма/счёт/дата);
- Формат передачи данных JSON;
- Перед отправкой сообщения должны валидироваться по схеме json-schema;
- Разные типы операций должны записываться в разные партиции топика;
- Продюсер должен быть максимально производительным и гарантировать доставку всех транзакций брокеру;
- В случае сбоя продюсер должен фиксировать в логе ошибку, смещение и партицию битого сообщения;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;

### Задание #2 (Потребители Kafka)
- Необходимо реализовать модуль для выгрузки объектов из Kafka;
- Конфигурирование потребителя должно быть вынесено в property-файл;
- В качестве данных необходимо сформировать объекты, описывающие транзакцию (тип операции/сумма/счёт/дата);
- Формат передачи данных JSON;
- Перед обработкой сообщения должны валидироваться по схеме json-schema;
- Потребитель должен быть максимально производительным и гарантировать обработку всех транзакций брокера;
- В случае сбоя продюсер потребитель должен фиксировать текущий offset и при перезапуске начинать читать с него же;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;
- 
### Ограничения
- Не используем Spring или другие верхнеуровневые библиотеки.

### Как работать над заданием?
- Создаёте от main свою новую ветку с типом release и с именем по шаблону "Фамилия_Модуль_Задание" (например: release/taranov_kafka_1);
- Клонируете проект из новой ветки в локальный репозиторий;
- Делаете доработки у себя в локальном репозитории;
- Заливаете свои доработки в новую feature ветку (например feature/taranov_kafka_1);
- Делаете PR в свою исходную релизную ветку (из которой клонировали проект);

### Условие успешной сдачи работы (критерии приемки)
- Проект компилируется и запускается;
- Результат review PR = approve.